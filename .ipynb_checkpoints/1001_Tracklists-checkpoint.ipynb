{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1001 Tracklists Scraper\n",
    "=======================\n",
    "A set of functions to scrape music tracklists from [1001 Tracklists](https://www.1001tracklists.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import a bunch of stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests \n",
    "import pandas as pd\n",
    "import urllib3\n",
    "import os\n",
    "import spotipy\n",
    "import spotipy.util as util\n",
    "from pprint import pprint\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get track data from spotify and return it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_id='6389b29d73fc4806ba5e812e678854c1'\n",
    "client_secret='0b4bcd832e694aedad408b5b4a93dd5c'\n",
    "ccm=util.oauth2.SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "sp =spotipy.Spotify(client_credentials_manager=ccm)\n",
    "\n",
    "def get_attrs(artist, track):\n",
    "    try:\n",
    "        res = sp.search(q='artist:'+artist+' track:'+track, type=\"track\")\n",
    "        track_res = res['tracks']['items'][0]\n",
    "        track_id = track_res['uri']\n",
    "        deets = sp.audio_features(track_id)\n",
    "        return pd.Series(deets[0])\n",
    "    except Exception as e:\n",
    "        return False\n",
    "    \n",
    "#get_attrs(artist='Armin Van Buuren', track=\"shivers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a tracklist from 1001 Tracklists and write it to a CSV with Spotify track info for all songs it can find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tracklist(url, folder='.'):\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    \n",
    "    !wget {url} -q\n",
    "    fname = url.split('/')[-1]\n",
    "    soup = bs(open(fname), \"lxml\")\n",
    "    !rm {fname}\n",
    "    \n",
    "    tracklist = pd.DataFrame(columns=['Artist(s)', 'Title', 'Release'])\n",
    "    set_name = soup.find(id=\"pageTitle\").get_text()\n",
    "    print(set_name)\n",
    "    \n",
    "    for div in soup.select('.trackValue'):\n",
    "        try:\n",
    "            text = div.get_text()\n",
    "            artists_raw = text.split('-')[0].split('&')\n",
    "            artists = \" \".join(artists_raw) \n",
    "            artists = artists.replace('vs.', ' ').strip()\n",
    "            #print(\"Artists: \"+artists)\n",
    "            \n",
    "            # title after '-' but before both label ([) and release (() and if a mashup, remove all but first song to make it easier to look up\n",
    "            title = text.split('-')[1].split('[')[0].split('(')[0].split('vs.')[0]\n",
    "            #print(\"title: \"+title)\n",
    "            \n",
    "            # Releases in braces\n",
    "            try:\n",
    "                release = text.split('(')[1].split(')')[0]\n",
    "            except:\n",
    "                release = \"Original Mix\"\n",
    "            #print(\"release: \"+release)\n",
    "            \n",
    "            # Label in []\n",
    "            try:\n",
    "                label = text.split('[')[1].split(']')[0]\n",
    "            except:\n",
    "                label = \"uknown\"\n",
    "\n",
    "            basic_details = pd.Series([artists, title, release], index=['Artist(s)', 'Title', 'Release'])\n",
    "            main_artist = artists.split(' ')[0]\n",
    "            spotify_details = get_attrs(artist=main_artist+' '+release, track=title)\n",
    "            # Try removing version if not found\n",
    "            if spotify_details is False:\n",
    "                spotify_details = get_attrs(artist=main_artist, track=title)\n",
    "            # Set details to none instead of false if not found, so track won't get excluded\n",
    "            if spotify_details is False:\n",
    "                spotify_details = None\n",
    "                print(f'Not Found: {title} by {artists}')\n",
    "            row = pd.concat([basic_details, spotify_details])\n",
    "            tracklist = tracklist.append(row, ignore_index=True)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass\n",
    "    tracklist.to_csv(f'{folder}/{set_name}.csv')\n",
    "    \n",
    "#get_tracklist(url='https://www.1001tracklists.com/tracklist/1kjuxf4t/giuseppe-ottaviani-go-on-air-fsoe-stage-tomorrowland-belgium-2018-08-21.html', folder='otaviani_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a whole series of tracklists, and put them in a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_series_tracklists(series_url, folder='.', recursecall=False):\n",
    "    !wget {series_url} -q\n",
    "    fname=series_url.split('/')[-1]\n",
    "    soup = bs(open(fname), \"lxml\")\n",
    "    !rm {fname}\n",
    "    main = soup.find(id='mainContentDiv')\n",
    "    for mix_link in main.find_all('a', href=True):\n",
    "        mix_href = mix_link['href']\n",
    "        if mix_href.startswith('/tracklist/'):\n",
    "            webpage = '/'.join(series_url.split('/')[0:3])\n",
    "            get_tracklist(webpage+mix_link['href'], folder=folder)\n",
    "        \n",
    "    if recursecall == False:\n",
    "        page_div = soup.find('ul', class_='pagination')\n",
    "        other_pages = page_div.find_all('a', href=True)\n",
    "        dont_follow = ['Prev', '1', 'Next']\n",
    "        for page in other_pages:\n",
    "            if page.get_text() not in dont_follow:\n",
    "                print(page['href'])\n",
    "                get_series_tracklists(webpage+mix_href+page['href'], folder=folder, recursecall=True)\n",
    "                \n",
    "get_series_tracklists(series_url='https://www.1001tracklists.com/groups/vgulwd/tomorrowland-2018/index2.html', folder='TomorrowLand2018')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
