{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1001 Tracklists Scraper\n",
    "=======================\n",
    "A set of functions to scrape music tracklists from [1001 Tracklists](https://www.1001tracklists.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import a bunch of stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests \n",
    "import pandas as pd\n",
    "import urllib3\n",
    "import os\n",
    "import spotipy\n",
    "import spotipy.util as util\n",
    "from pprint import pprint\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get track data from spotify and return it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_id='6389b29d73fc4806ba5e812e678854c1'\n",
    "client_secret='0b4bcd832e694aedad408b5b4a93dd5c'\n",
    "ccm=util.oauth2.SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "sp =spotipy.Spotify(client_credentials_manager=ccm)\n",
    "\n",
    "def get_attrs(artist, track):\n",
    "    try:\n",
    "        res = sp.search(q='artist:'+artist+' track:'+track, type=\"track\")\n",
    "        track_res = res['tracks']['items'][0]\n",
    "        track_id = track_res['uri']\n",
    "        deets = sp.audio_features(track_id)\n",
    "        return pd.Series(deets[0])\n",
    "    except Exception as e:\n",
    "        return False\n",
    "    \n",
    "#get_attrs(artist='Armin Van Buuren', track=\"shivers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a tracklist from 1001 Tracklists and write it to a CSV with Spotify track info for all songs it can find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tracklist(url, folder='.'):\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    \n",
    "    !wget {url} -q\n",
    "    fname = url.split('/')[-1]\n",
    "    soup = bs(open(fname), \"lxml\")\n",
    "    !rm {fname}\n",
    "    \n",
    "    tracklist = pd.DataFrame(columns=['Artist(s)', 'Title', 'Release'])\n",
    "    set_name = soup.find(id=\"pageTitle\").get_text()\n",
    "    print(set_name)\n",
    "    \n",
    "    for div in soup.select('.trackValue'):\n",
    "        try:\n",
    "            text = div.get_text()\n",
    "            artists_raw = text.split('-')[0].split(' & ')\n",
    "            artists = \" \".join(artists_raw) \n",
    "            artists = artists.replace('vs.', ' ').strip()\n",
    "            artists = artists.replace('ft.', ' ')\n",
    "            #print(\"Artists: \"+artists)\n",
    "            \n",
    "            # title after '-' but before both label ([) and release (() and if a mashup, remove all but first song to make it easier to look up\n",
    "            title = text.split('-')[1].split('[')[0].split('(')[0].split('vs.')[0]\n",
    "            #print(\"title: \"+title)\n",
    "            \n",
    "            # Releases in braces\n",
    "            try:\n",
    "                release = text.split('(')[1].split(')')[0]\n",
    "            except:\n",
    "                release = \"unknown\"\n",
    "            #print(\"release: \"+release)\n",
    "            \n",
    "            # Label in []\n",
    "            try:\n",
    "                label = text.split('[')[1].split(']')[0]\n",
    "            except:\n",
    "                label = \"uknown\"\n",
    "\n",
    "            basic_details = pd.Series([artists, title, release], index=['Artist(s)', 'Title', 'Release'])\n",
    "            \n",
    "            #don't search spotify for unknown version, just search base name\n",
    "            if release == 'unknown':\n",
    "                release = ''\n",
    "                \n",
    "            spotify_details = get_attrs(artist=artists+' '+release, track=title)\n",
    "            # Try removing version if not found\n",
    "            if spotify_details is False:\n",
    "                for a in artists.split(' '):\n",
    "                    spotify_details = get_attrs(artist=a, track=title)\n",
    "                    if spotify_details is not False:\n",
    "                        break\n",
    "            # Set details to none instead of false if not found, so track won't get excluded\n",
    "            if spotify_details is False:\n",
    "                spotify_details = None\n",
    "                print(f'Not Found: {title} by {artists}')\n",
    "            row = pd.concat([basic_details, spotify_details])\n",
    "            tracklist = tracklist.append(row, ignore_index=True)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass\n",
    "    tracklist.to_csv(f'{folder}/{set_name}.csv')\n",
    "    \n",
    "#get_tracklist(url='https://www.1001tracklists.com/tracklist/1kjuxf4t/giuseppe-ottaviani-go-on-air-fsoe-stage-tomorrowland-belgium-2018-08-21.html', folder='otaviani_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a whole series of tracklists, and put them in a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-10-05 15:50:48--  https://www.1001tracklists.com/groups/4u1f7w/ultra-music-festival-singapore-2018/index.html\n",
      "Resolving www.1001tracklists.com (www.1001tracklists.com)... 158.69.5.7\n",
      "Connecting to www.1001tracklists.com (www.1001tracklists.com)|158.69.5.7|:443... connected.\n",
      "HTTP request sent, awaiting response... 403 Forbidden\n",
      "2018-10-05 15:50:48 ERROR 403: Forbidden.\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'index.html'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-e775519e4114>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mget_series_tracklists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'href'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursecall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mget_series_tracklists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'https://www.1001tracklists.com/groups/4u1f7w/ultra-music-festival-singapore-2018/index.html'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'TomorrowLand2018'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-e775519e4114>\u001b[0m in \u001b[0;36mget_series_tracklists\u001b[0;34m(series_url, folder, recursecall)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wget {series_url} '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mfname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseries_url\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lxml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rm {fname}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mainContentDiv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'index.html'"
     ]
    }
   ],
   "source": [
    "def get_series_tracklists(series_url, folder='.', recursecall=False):\n",
    "    !wget {series_url} \n",
    "    fname=series_url.split('/')[-1]\n",
    "    soup = bs(open(fname), \"lxml\")\n",
    "    !rm {fname}\n",
    "    main = soup.find(id='mainContentDiv')\n",
    "    for mix_link in main.find_all('a', href=True):\n",
    "        mix_href = mix_link['href']\n",
    "        if mix_href.startswith('/tracklist/'):\n",
    "            webpage = '/'.join(series_url.split('/')[0:3])\n",
    "            print(mix_href)\n",
    "            #get_tracklist(webpage+mix_link['href'], folder=folder)\n",
    "        \n",
    "    if recursecall == False:\n",
    "        page_div = soup.find('ul', class_='pagination')\n",
    "        other_pages = page_div.find_all('a', href=True)\n",
    "        dont_follow = ['Prev', '1', 'Next']\n",
    "        for page in other_pages:\n",
    "            if page.get_text() not in dont_follow: #and mix_href != '/info/cookies.html':\n",
    "                group = series_url[0:rfind('/')]\n",
    "                print(group)\n",
    "                get_series_tracklists(group+page['href'], folder=folder, recursecall=True)\n",
    "                \n",
    "get_series_tracklists(series_url='https://www.1001tracklists.com/groups/4u1f7w/ultra-music-festival-singapore-2018/index.html', folder='TomorrowLand2018')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
