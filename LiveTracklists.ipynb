{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1001 Tracklists Scraper\n",
    "=======================\n",
    "A set of functions to scrape music tracklists from [1001 Tracklists](https://www.1001tracklists.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import a bunch of stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests \n",
    "import pandas as pd\n",
    "import urllib3\n",
    "import os\n",
    "import spotipy\n",
    "import spotipy.util as util\n",
    "import traceback\n",
    "from pprint import pprint\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_url = 'https://www.livetracklist.com/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get track data from spotify and return it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_id='6389b29d73fc4806ba5e812e678854c1'\n",
    "client_secret='0b4bcd832e694aedad408b5b4a93dd5c'\n",
    "ccm=util.oauth2.SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "sp =spotipy.Spotify(client_credentials_manager=ccm)\n",
    "\n",
    "def get_attrs(artist, track):\n",
    "    try:\n",
    "        res = sp.search(q='artist:'+artist+' track:'+track, type=\"track\")\n",
    "        track_res = res['tracks']['items'][0]\n",
    "        track_id = track_res['uri']\n",
    "        deets = sp.audio_features(track_id)\n",
    "        camelot = get_camelot(deets[0]['key'], deets[0]['mode'])\n",
    "        deets[0]['camelot'] = camelot\n",
    "        return pd.Series(deets[0])\n",
    "    except Exception as e:\n",
    "        #print(e)\n",
    "        return False\n",
    "    \n",
    "#get_attrs(artist='Armin Van Buuren', track=\"shivers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_camelot(key, mode):\n",
    "    # index of letter is spotify pitch class - e.g. 0->c, 1->c# etc.\n",
    "    tones = [ 'c', 'c#', 'd', 'd#', 'e', 'f', 'f#', 'g', 'g#', 'a', 'a#', 'b' ]\n",
    "    keys = {\n",
    "        'a0': '8A',\n",
    "        'a1': '11B',\n",
    "        'a#0': '3A',\n",
    "        'a#1': '6B',\n",
    "        'b0': '10A',\n",
    "        'b1': '1B',\n",
    "        'c0': '5A',\n",
    "        'c1': '8B',\n",
    "        'c#0': '12A',\n",
    "        'c#1': '3B',\n",
    "        'd0': '7A',\n",
    "        'd1': '10B',\n",
    "        'd#0': '2A',\n",
    "        'd#1': '5B',\n",
    "        'e0': '9A',\n",
    "        'e1': '12B',\n",
    "        'f0': '4A',\n",
    "        'f1': '7B',\n",
    "        'f#0': '11A',\n",
    "        'f#1': '2B',\n",
    "        'g0': '6A',\n",
    "        'g1': '9B',\n",
    "        'g#0': '1A',\n",
    "        'g#1': '4B',\n",
    "    }\n",
    "    key_letter = tones[key]\n",
    "    return keys[key_letter+str(mode)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a tracklist from 1001 Tracklists and write it to a CSV with Spotify track info for all songs it can find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tracklist(url, folder='.'):\n",
    "    try:\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "        fname = url.split('/')[-2]\n",
    "\n",
    "        !wget {url} -q -O {fname}\n",
    "        #print(\"Fname: \"+fname)\n",
    "        soup = bs(open(fname), \"lxml\")\n",
    "        !rm {fname}\n",
    "\n",
    "        tracklist = pd.DataFrame(columns=['Artist(s)', 'Title', 'Release'])\n",
    "        set_name = soup.find(class_=\"entry-title\").get_text().strip()\n",
    "        print(set_name)\n",
    "        if os.path.exists(f'{folder}/{set_name}.csv'):\n",
    "            print(f'Skipping: {set_name}, already exists...')\n",
    "            return    \n",
    "        for li in soup.select('#TheList')[0].find_all('li'):\n",
    "            try:\n",
    "                link = li.find('span', class_='listItem')\n",
    "                if link is None:\n",
    "                    continue\n",
    "                text = link.get_text()\n",
    "                artists_raw = text.split('-')[0].split(' & ')\n",
    "                artists = \" \".join(artists_raw) \n",
    "                artists = artists.replace('vs.', ' ').strip()\n",
    "                artists = artists.replace('ft.', ' ')\n",
    "                #print(\"Artists: \"+artists)\n",
    "\n",
    "                # title after '-' but before both label ([) and release (() and if a mashup, remove all but first song to make it easier to look up\n",
    "                title = text.split('-')[1].split('[')[0].split('(')[0].split('vs.')[0]\n",
    "                #print(\"title: \"+title)\n",
    "\n",
    "                # Releases in braces\n",
    "                try:\n",
    "                    release = text.split('(')[1].split(')')[0]\n",
    "                except:\n",
    "                    release = \"unknown\"\n",
    "                #print(\"release: \"+release)\n",
    "\n",
    "                # Label in []\n",
    "                try:\n",
    "                    label = text.split('[')[1].split(']')[0]\n",
    "                except:\n",
    "                    label = \"uknown\"\n",
    "\n",
    "                basic_details = pd.Series([artists, title, release], index=['Artist(s)', 'Title', 'Release'])\n",
    "\n",
    "                #don't search spotify for unknown version, just search base name\n",
    "                if release == 'unknown':\n",
    "                    release = ''\n",
    "\n",
    "                spotify_details = get_attrs(artist=artists+' '+release, track=title)\n",
    "                # Try removing version if not found\n",
    "                if spotify_details is False:\n",
    "                    for a in artists.split(' '):\n",
    "                        spotify_details = get_attrs(artist=a, track=title)\n",
    "                        if spotify_details is not False:\n",
    "                            break\n",
    "                # Set details to none instead of false if not found, so track won't get excluded\n",
    "                if spotify_details is False:\n",
    "                    spotify_details = None\n",
    "                    print(f'Not Found: {title} by {artists}')\n",
    "                row = pd.concat([basic_details, spotify_details])\n",
    "                tracklist = tracklist.append(row, ignore_index=True)\n",
    "            except Exception as e:\n",
    "                traceback.print_exc()\n",
    "                pass\n",
    "        tracklist.to_csv(f'{folder}/{set_name}.csv')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "#get_tracklist(url='https://www.livetracklist.com/lost-frequencies-slam-mixmarathon-xxl-ade-2018/', folder='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a whole series of tracklists, and put them in a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_series_tracklists(series_url):\n",
    "    for page in range(310):\n",
    "        fname = str(page)\n",
    "        doesnt_exist = !ls | grep fname\n",
    "        if doesnt_exist != 0:\n",
    "            !wget {series_url+'/page/'+str(page)} \n",
    "            soup = bs(open(fname), \"lxml\")\n",
    "            !rm {fname}\n",
    "        else:\n",
    "            print(fname+\" already exists, skipping...\")\n",
    "        main = soup.find(class_='cb-main')\n",
    "        title = \"LiveTracklists\"\n",
    "        for article in main.find_all('article'):\n",
    "            link = article.find('a', href=True)\n",
    "            href = link['href']\n",
    "            print(\"href: \"+href)\n",
    "            get_tracklist(url=href, folder=title)\n",
    "\n",
    "                \n",
    "get_series_tracklists(series_url=root_url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
